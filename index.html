<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>CV Léa Aumagy</title>
    <link rel="icon" type="image/x-icon" href="favicon.ico" />
    <!-- Font Awesome icons (free version) -->
    <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
    <!-- Google fonts -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
    <!-- Core theme CSS (includes Bootstrap) -->
    <link href="styles.css" rel="stylesheet" />
</head>
<body id="page-top">
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">
            <span class="d-block d-lg-none">Léa Aumagy</span>
            <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="photo.jpg" alt="..." /></span>
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">À propos</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#experiences">Expériences</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#formations">Formations</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#competences">Compétences</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#projects">Projets</a></li>
            </ul>
        </div>
		  <img class="img-fluid mx-auto my-2" src="computer_science.jpg">
		  <div>
		  
		  </div>
    </nav>
    <!-- Page Content -->
    <div class="container-fluid p-0">
        <!-- À propos -->
        <section class="resume-section" id="about">
            <div class="resume-section-content">
                <h1 class="mb-0">
					 	L<span style="text-transform: lowercase;">éa</span>
						 <span class="text-primary">Aumagy</span>
					</h1>
							 <a href="mailto:lea.aumagy@etu.univ-amu.fr">lea.aumagy@etu.univ-amu.fr</a>
							 <br>
							 <br>
                <p class="lead mb-5">Passionnée par la data et les statistiques et dotée d'une solide formation dans ces domaines complétée par une alternance d'aide à la décision, je suis prête à mettre mes compétences au service de votre entreprise dans le domaine de la data science. </p>
                <div class="social-icons">
                    <a class="social-icon" href="https://www.linkedin.com/in/l%C3%A9a-aumagy-9297771b8/"><i class="fab fa-linkedin-in"></i></a>
                    <a class="social-icon" href="https://github.com/leaaumagy"><i class="fab fa-github"></i></a>
                </div>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Expériences -->
        <section class="resume-section" id="experiences">
            <div class="resume-section-content">
                <h2 class="mb-5">Expériences</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
					    <div class="flex-grow-1">
					        <h3 class="mb-0">Data Scientist</h3>
					        <div class="subheading mb-3">Direction Zonale de la Police Nationale Sud</div>
					        <p><strong>Stage, Alternance puis CDD.</strong></p>
					        <p><strong>Projet :</strong> Études statistiques et implémentations d’algorithmes de machine learning d’aide à la décision.</p>
					        <p>Études statistiques d'aide à la décision pour les 21 départements (DDPN) des régions Occitanie et PACA et pour évaluer les objectifs ministériels liés aux lois de finances.</p>
					        
					        <p><strong>Réalisations :</strong></p>
					        <ul>
					            <li><strong>Analyse des indicateurs de performance :</strong> Identification des leviers d'optimisation des ressources et amélioration de l'efficacité des services.</li>
					            
					            <li><strong>Mise en place d’un outil basé sur du machine learning :</strong>
					                <ul>
					                    <li>Analyse littéraire de travaux de recherche basés sur la prédiction sur Google Scholar.</li>
					                    <li>Implémentation et test de différents modèles de machine learning.</li>
					                    <li>Développement d’un modèle d’apprentissage automatique utilisant l’analyse de composantes principales pour identifier des services similaires.</li>
					                    <li>Création d'un outil interactif en RShiny permettant à l’utilisateur de sélectionner des indicateurs pour classer les services selon les critères choisis.</li>
					                    <li>Simulation de taux de criminalité avec ajustements des indicateurs pour estimer l'impact de différentes variables (ex. : augmentation des heures de patrouille).</li>
					                    <li>Outil utilisé pour déterminer l’affectation des Officiers de Police Judiciaire.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Création de tableaux de bord :</strong>
					                <ul>
					                    <li>Identification des indicateurs de performance.</li>
					                    <li>Recueil et nettoyage des données.</li>
					                    <li>Création de tableaux de bord par filière (ex. : Police Nationale, Sécurité Publique).</li>
					                    <li>Création de maquettes pour faciliter la mise à jour interne des données.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Soutien aux différents services :</strong>
					                <ul>
					                    <li>Création et sauvegarde de requêtes SQL sur SAP BusinessObject pour fournir des tableaux aux agents.</li>
					                    <li>Automatisation des tâches en VBA, simplification des processus répétitifs.</li>
					                    <li>Formation des équipes à Excel et autres outils internes.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Participation au développement et aux suggestions pour de nouveaux outils :</strong>
					                <ul>
					                    <li>Utilisation de Docker pour la mise en place d'environnements de développement.</li>
					                    <li>Participation aux visioconférences pour discuter des nouveaux outils.</li>
					                    <li>Suggestions d'améliorations pour fluidifier l’utilisation des applications internes.</li>
					                </ul>
					            </li>
					        </ul>
					        
					        <p><strong>Environnement technique et méthodologique :</strong> Python, R, RShiny, HTML/CSS, SQL, SAP BusinessObject, Power BI, Docker, Machine Learning, Linux</p>
					    </div>
					    <div class="flex-shrink-0"><span class="date">Mai 2023 - Décembre 2024</span></div>
					</div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
					    <div class="flex-grow-1">
					        <h3 class="mb-0">Assistante de recherche</h3>
					        <div class="subheading mb-3">Aix-Marseille School of Economics</div>
					        <p><strong>Stage</strong></p>
					        
					        <p><strong>Projet :</strong> Simulation de différents systèmes de vote pour atteindre un niveau de bien-être social optimal.</p>
					        <p>Ce projet avait pour objectif de comparer divers systèmes de vote dans le cadre d’une recherche universitaire en théorie des jeux afin de déterminer lequel procure le niveau optimal de bien-être social. Sous la supervision d’un enseignant-chercheur, j’ai contribué en développant des simulations et en analysant les résultats.</p>
					        
					        <p><strong>Réalisations :</strong></p>
					        <ul>
					            <li><strong>Recherche et analyse théorique :</strong>
					                <ul>
					                    <li>Étude approfondie des systèmes de vote existants, avec un focus particulier sur le jugement majoritaire.</li>
					                    <li>Analyse des fondements théoriques et de l'impact potentiel de chaque système sur le bien-être social et la satisfaction collective.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Développement d’algorithmes de simulation en Python :</strong>
					                <ul>
					                    <li>Conception d'algorithmes simulant les choix électoraux des individus sous différents systèmes de vote, avec attribution d’utilité pour quantifier les préférences.</li>
					                    <li>Implémentation de divers scénarios en appliquant des distributions statistiques (loi uniforme, loi normale) pour simuler la répartition des préférences électorales.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Analyse des résultats des simulations :</strong>
					                <ul>
					                    <li>Évaluation des systèmes électoraux en fonction du bien-être social, avec identification de celui qui maximise la satisfaction des électeurs.</li>
					                    <li>Analyse comparative pour établir des corrélations entre le type de système de vote et le niveau d’utilité sociale obtenu.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Rédaction d’une synthèse de recherche :</strong>
					                <ul>
					                    <li>Compilation des résultats dans une synthèse détaillée, avec graphiques et interprétations, démontrant l'impact des systèmes de vote sur le bien-être social.</li>
					                    <li>Contributions à la documentation pour soutenir les travaux du chercheur, en fournissant des éléments empiriques en appui aux théories étudiées.</li>
					                </ul>
					            </li>
					        </ul>
					        
					        <p><strong>Environnement technique et méthodologique :</strong> Python, Mathématiques / Statistiques, Google Scholar</p>
					    </div>
					    <div class="flex-shrink-0"><span class="date">Mai 2022 - Juillet 2022</span></div>
					</div>

            </div>
        </section>
        <hr class="m-0" />
        <!-- Formations -->
        <section class="resume-section" id="formations">
            <div class="resume-section-content">
                <h2 class="mb-5">Formations</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Master Économie parcours Économétrie, Big Data et Statistiques</h3>
                        <div class="subheading mb-3">Aix-Marseille School of Economics, Marseille </div>
                       	<ul>
									<li>1ère année en formation initiale.</li>
									<li>2ème année en formation continue et en anglais.</li>
								</ul>
                    </div>
                    <div class="flex-shrink-0"><span class="date">Septembre 2022 - Août 2024</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Licence d'Économie et de Gestion parcours Économie-Finance</h3>
                        <div class="subheading mb-3">Faculté d'Économie et de Gestion, Marseille</div>
                        <ul>
									<li>Double formation entre la licence 3 Économie-Finance et le Magistère 1 Ingénieur Économiste.</li>
									<li>Double formation entre la licence 1 et 2 et la classe préparatoire ENS D2.</li>
								</ul>
                    </div>
                    <div class="flex-shrink-0"><span class="date">Septembre 2019 - Mai 2022</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">CPGE ENS D2</h3>
                        <div class="subheading mb-3">Lycée Jean-Perrin, Marseille</div>
                        <ul><li>Formation dédiée à la préparation de divers concours, notamment l'ENS Paris-Saclay, l'ENSAI, l'EDHEC, ainsi que les écoles de commerce et de management. </li></ul>
                    </div>
                    <div class="flex-shrink-0"><span class="date">Septembre 2019 - Avril 2021</span></div>
                </div>
            </div>
        </section>
        <hr class="m-0" />
       <!-- Compétences -->
		<section class="resume-section" id="competences">
		    <div class="resume-section-content">
		        <h2 class="mb-5">Compétences</h2>
		
		        <!-- Compétences Techniques -->
		        <div class="subheading mb-3">Langages de Programmation et Bases de Données</div>
		        <ul class="fa-ul mb-0">
		            <li><span class="fa-li"><i class="fab fa-r-project"></i></span>
		                <strong>R :</strong> Analyse statistique avec ggplot2 et dplyr, développement d'applications interactives avec Shiny.
		            </li>
		            <li><span class="fa-li"><i class="fab fa-python"></i></span>
		                <strong>Python :</strong> Manipulation de données avec Pandas et Numpy, développement de modèles de machine learning avec Scikit-Learn et TensorFlow, web scraping avec BeautifulSoup, ainsi que des modèles de deep learning.
		            </li>
		            <li><span class="fa-li"><i class="fas fa-database"></i></span>
		                <strong>SQL/NoSQL :</strong> Requêtes SQL sur MySQL et BigQuery.
		            </li>
		            <li><span class="fa-li"><i class="fab fa-linux"></i></span>
		                <strong>Linux :</strong> Gestion de l'environnement de développement.
		            </li>
		            <li><span class="fa-li"><i class="fab fa-google"></i></span>
		                <strong>Google Cloud Platform :</strong> BigQuery pour l'analyse de données, déploiement de modèles et gestion d’infrastructures, et Looker Studio pour la création de tableaux de bord.
		            </li>
		            <li><span class="fa-li"><i class="fab fa-docker"></i></span>
		                <strong>Docker :</strong> Création de conteneurs pour déployer des applications et assurer la portabilité des environnements.
		            </li>
						<li><span class="fa-li"><i class="fas fa-file-code"></i></span>
		                <strong>LaTeX :</strong> Rédaction technique et mise en forme de documents scientifiques.
		            </li>
		            <li><span class="fa-li"><i class="fab fa-microsoft"></i></span>
		                <strong>Microsoft Office :</strong> Utilisation avancée d'Excel et VBA.
		            </li>
		            <li><span class="fa-li"><i class="fas fa-chart-line"></i></span>
		                <strong>Tableau</strong> 
		            </li>
		            <li><span class="fa-li"><i class="fas fa-chart-bar"></i></span>
		                <strong>Power BI</strong>
		            </li>
		        </ul>
		        <p>  </p>
		
		        <!-- Outils de Data Science et Visualisation -->
		        <div class="subheading mb-3">Compétences Techniques</div>
		        <ul class="fa-ul mb-0">
		            <li><span class="fa-li"><i class="fas fa-chart-bar"></i></span><strong>Tableaux de bord :</strong> Power BI, Tableau, Looker Studio</li>
		            <li><span class="fa-li"><i class="fas fa-cogs"></i></span><strong>Visualisation :</strong> Plotly, Matplotlib, Seaborn, Dash, Shiny</li>
		            <li><span class="fa-li"><i class="fas fa-toolbox"></i></span><strong>Machine Learning :</strong> Scikit-Learn, TensorFlow, XGBoost</li>
		            <li><span class="fa-li"><i class="fas fa-brain"></i></span><strong>Deep Learning :</strong> NLP, BART, BERT, Computer Vision, YOLO, Transfert Learning, Hugging Face Transformers, métrique ROUGE, mAP, F1-score</li>
		        </ul>
		        <p>  </p>
		
		        <!-- Workflow et Compétences Transversales -->
		        <div class="subheading mb-3">Workflow et Compétences Transversales</div>
		        <ul class="fa-ul mb-0">
		            <li><span class="fa-li"><i class="fas fa-check"></i></span>Capacité d'analyse et de synthèse</li>
		            <li><span class="fa-li"><i class="fas fa-check"></i></span>Travail d'équipe et collaboration avec des parties prenantes</li>
		            <li><span class="fa-li"><i class="fas fa-check"></i></span>Gestion de projets et méthodologies agiles (Scrum)</li>
		            <li><span class="fa-li"><i class="fas fa-check"></i></span>Méthodes statistiques appliquées</li>
		            <li><span class="fa-li"><i class="fas fa-check"></i></span>Documentation et reporting</li>
		        </ul>
		    </div>
		</section>
		<hr class="m-0" />


        <!-- Projets -->
        <section class="resume-section" id="projects">
            <div class="resume-section-content">
                <h2 class="mb-5">Projets</h2>
					 <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
					    <div class="flex-grow-1">
					        <h3 class="mb-0">Hackathon IA 2024 - AIRBUS</h3>
					        <div class="subheading mb-3">Aix-Marseille School of Economics / Airbus – Marseille</div>
					        
					        <p><strong>Projet :</strong> Hackathon Intelligence Artificielle 2024</p>
					        <p>Développement d'un algorithme de traitement automatique du langage naturel (NLP) en équipe pour résumer des documents légaux (corpus de texte) sur une durée limitée d'une semaine.</p>
					        
					        <p><strong>Réalisations :</strong></p>
					        <ul>
					            <li><strong>Conception de la pipeline NLP :</strong>
					                <ul>
					                    <li>Nettoyage des données avec prétraitement des documents légaux pour enlever le bruit et normaliser le texte afin de faciliter l'analyse.</li>
					                    <li>Préparation des textes en utilisant des techniques de tokenization.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Résumé automatique avec techniques de NLP avancées :</strong>
					                <ul>
					                    <li>Mise en place d’un modèle NLP basé sur BART pour générer un résumé pertinent, surpassant d'autres modèles en termes de cohérence et de précision.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Évaluation de la qualité et optimisation du modèle :</strong>
					                <ul>
					                    <li>Utilisation des scores ROUGE (Recall-Oriented Understudy for Gisting Evaluation) pour évaluer la qualité des résumés générés en les comparant à des résumés humains de référence.</li>
					                    <li>Optimisation des hyper-paramètres pour maximiser la pertinence des résumés et minimiser le temps de traitement.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Gestion du projet :</strong>
					                <ul>
					                    <li>Répartition des tâches entre les membres de l'équipe avec des points de synchronisation quotidiens pour intégrer les avancées de chacun.</li>
					                </ul>
					            </li>
					        </ul>
					        
					        <p><strong>Environnement technique et méthodologique :</strong> Python, NLP, BERT, BART, Deep Learning, Hugging Face Transformers, métrique d’évaluation ROUGE</p>
					    </div>
					    <div class="flex-shrink-0"><span class="date">Février 2024</span></div>
					</div>

					 <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
					    <div class="flex-grow-1">
					        <h3 class="mb-0">Détection de logo sur des vidéos</h3>
					        <div class="subheading mb-3">Aix-Marseille School of Economics – Marseille</div>
					        
					        <p><strong>Projet :</strong> Détection de logo sur des vidéos</p>
							  <p><a href="https://github.com/leaaumagy/Logo-detection-with-yolov8-on-youtube-videos" target="_blank">GitHub - Logo detection</a></p>
					        <p>Identification des marques présentes au sein de vidéos grâce aux logos visibles pour cibler des profils de clients. Ce type de détection est particulièrement utile pour le suivi des marques dans les diffusions télévisées, les réseaux sociaux ou les événements en direct, permettant un ciblage précis des profils consommateurs.</p>
					        
					        <p><strong>Réalisations :</strong></p>
					        <ul>
					            <li><strong>Collecte et préparation des données :</strong>
					                <ul>
					                    <li><strong>Acquisition des données :</strong> Recueil et rassemblement de milliers d’images représentant un large panel de logos, accompagnées d’annotations XML précises.</li>
					                    <li><strong>Prétraitement des données :</strong> Conversion des annotations XML au format YAML, compatible avec le framework YOLO, et normalisation des images pour assurer une cohérence dimensionnelle.</li>
					                    <li><strong>Équilibrage des classes :</strong> Duplication d’images pour sous-représenter certaines classes, réduction des biais de classe, et suppression des doublons pour garantir un ensemble d’entraînement équilibré.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Développement et optimisation du modèle :</strong>
					                <ul>
					                    <li>Utilisation du modèle YOLOv8 avec Transfert Learning pour adapter un modèle pré-entraîné à la tâche spécifique de détection de logos.</li>
					                    <li>Ajustement des hyperparamètres pour maximiser la précision de la détection des logos.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Évaluation de la qualité et optimisation du modèle :</strong>
					                <ul>
					                    <li>Utilisation des métriques de mAP (mean Average Precision) et F1-score pour évaluer la précision et la pertinence de la détection.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Documentation :</strong>
					                <ul>
					                    <li>Création d’une documentation détaillée couvrant le processus de développement, incluant les choix d'architecture et les résultats obtenus pour faciliter l’utilisation et la modification du projet.</li>
					                </ul>
					            </li>
					        </ul>
					        
					        <p><strong>Environnement technique et méthodologique :</strong> Python, Computer Vision, Deep Learning, YOLOv8, données XML et YAML, métriques d’évaluation mAP et F1-score, utilisation d’un GPU</p>
					    </div>
					    <div class="flex-shrink-0"><span class="date">Décembre 2023</span></div>
					</div>

					<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
					    <div class="flex-grow-1">
					        <h3 class="mb-0">Prédiction du nombre de passagers dans le métro New-Yorkais</h3>
					        <div class="subheading mb-3">Aix-Marseille School of Economics – Marseille</div>
					        
					        <p><strong>Projet :</strong> Prédiction de l'affluence dans le métro new-yorkais</p>
					        <p><a href="https://github.com/leaaumagy/Subway target="_blank">GitHub - Subway</a></p>
							  <p>Développement d'un modèle prédictif exploitant des données historiques pour anticiper l'affluence dans le métro new-yorkais, basé sur des facteurs socio-économiques, météorologiques, et saisonniers. Ce modèle permet d’optimiser la gestion des ressources et la planification des horaires.</p>
					        
					        <p><strong>Réalisations :</strong></p>
					        <ul>
					            <li><strong>Collecte et exploration des données :</strong>
					                <ul>
					                    <li><strong>Source des données :</strong> Intégration de données du MTA (trafic journalier), de données météorologiques, et de variables socio-économiques.</li>
					                    <li><strong>Nettoyage et prétraitement :</strong> Gestion des valeurs manquantes, détection des anomalies, et normalisation des variables pour aligner les échelles.</li>
					                    <li><strong>Analyse exploratoire des données (EDA) :</strong> Visualisation des tendances saisonnières, hebdomadaires et identification de corrélations entre affluence et conditions météorologiques.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Modélisation de différents modèles de machine learning :</strong>
					                <ul>
					                    <li><strong>Modèles paramétriques :</strong>
					                        <ul>
					                            <li><strong>Régression linéaire :</strong> Création d'un modèle de régression linéaire pour une première estimation de la fréquentation.</li>
					                            <li><strong>Réduction de dimension avec Lasso :</strong> Sélection de variables pour réduire la variance, en identifiant les facteurs clés tels que les jours de la semaine ou les températures extrêmes.</li>
					                        </ul>
					                    </li>
					                    <li><strong>Modèles non paramétriques :</strong>
					                        <ul>
					                            <li><strong>Arbres de décision avec XGBoost :</strong> Implémentation de XGBoost pour capturer les non-linéarités et interactions complexes entre variables.</li>
					                            <li><strong>Validation croisée :</strong> Optimisation des hyperparamètres du modèle XGBoost pour maximiser la performance prédictive.</li>
					                        </ul>
					                    </li>
					                </ul>
					            </li>
					            
					            <li><strong>Interprétation des modèles :</strong>
					                <ul>
					                    <li>Utilisation de la méthode SHAP (Shapley Additive Explanations) pour analyser la contribution individuelle de chaque variable dans les prédictions.</li>
					                    <li>Analyse des résultats pour identifier les facteurs influents, fournissant des recommandations pour la gestion des flux de passagers.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Développement d’une Interface Interactive de visualisation :</strong>
					                <ul>
					                    <li>Conception d'un tableau de bord dynamique avec Python, HTML, CSS et Dash/Plotly, permettant aux utilisateurs de visualiser les prévisions en fonction des dates et conditions météorologiques.</li>
					                </ul>
					            </li>
					        </ul>
					        
					        <p><strong>Environnement technique et méthodologique :</strong> Python (Pandas, Numpy, Dash, Plotly), HTML/CSS, Machine learning, Régression linéaire, Lasso, XGBoost, méthode SHAP, métriques de performance avec RMSE et R²</p>
					    </div>
					    <div class="flex-shrink-0"><span class="date">Décembre 2023 - Janvier 2024</span></div>
					</div>
					<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
					    <div class="flex-grow-1">
					        <h3 class="mb-0">Scraping de données avec "Books to Scrape"</h3>
					        <div class="subheading mb-3">Aix-Marseille School of Economics - Marseille</div>
					        
					        <p><strong>Projet :</strong> Extraction de données de livres sur le site "Books to Scrape"</p>
							  <p><a href="https://github.com/leaaumagy/Books-to-scrape/tree/main" target="_blank">GitHub - Books to Scrape</a></p>
					        <p>Développement d'un script Python pour extraire les informations de livres (titre, prix, disponibilité, etc.) du site "Books to Scrape" et les organiser dans un format structuré pour une analyse ultérieure.</p>
					        
					        <p><strong>Réalisations :</strong></p>
					        <ul>
					            <li><strong>Collecte et extraction des données :</strong>
					                <ul>
					                    <li><strong>Accès aux données :</strong> Utilisation de BeautifulSoup pour extraire les éléments HTML et accéder aux informations sur chaque livre (titre, prix, notation, disponibilité).</li>
					                    <li><strong>Navigation sur le site :</strong> Implémentation de la navigation entre les pages pour extraire l’ensemble des livres, en automatisant le processus pour parcourir toutes les catégories.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Traitement et stockage des données :</strong>
					                <ul>
					                    <li>Organisation des données extraites dans un format structuré (CSV) pour une analyse et une visualisation simplifiées.</li>
					                    <li>Ajout de contrôles d'erreur pour gérer les pages manquantes et garantir l'intégrité des données collectées.</li>
					                </ul>
					            </li>
					            
					            <li><strong>Documentation et optimisation :</strong>
					                <ul>
					                    <li>Création d'une documentation détaillée pour décrire le processus de scraping, l'organisation des données et les techniques d’optimisation utilisées.</li>
					                </ul>
					            </li>
					        </ul>
					        
					        <p><strong>Environnement technique et méthodologique :</strong> Python, BeautifulSoup, requests, gestion des erreurs, exportation CSV, GitHub</p>
					    </div>
					    <div class="flex-shrink-0"><span class="date">Novembre 2023</span></div>
					</div>

						<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
						    <div class="flex-grow-1">
						        <h3 class="mb-0">Gestion de bases relationnelles et Visualisation de données</h3>
						        <div class="subheading mb-3">Aix-Marseille School of Economics - Marseille</div>
						        
						        <p><strong>Projet :</strong> Création de tableaux de bord dynamiques à partir de requêtes SQL sur Google Cloud BigQuery</p>
						        <p>Conception et exécution de requêtes SQL sur Google Cloud BigQuery pour extraire et analyser des données, suivie de la création d’un tableau de bord dynamique sur Looker Studio, permettant aux utilisateurs finaux de visualiser les résultats en temps réel.</p>
						        
						        <p><strong>Réalisations :</strong></p>
						        <ul>
						            <li><strong>Requêtes SQL sur BigQuery :</strong>
						                <ul>
						                    <li>Conception de requêtes SQL avancées pour extraire des données pertinentes et effectuer des analyses, telles que les agrégations, jointures, et filtres complexes.</li>
						                    <li>Optimisation des requêtes pour réduire le coût de calcul dans BigQuery et améliorer la rapidité d'exécution.</li>
						                </ul>
						            </li>
						            
						            <li><strong>Intégration et visualisation des données sur Looker Studio :</strong>
						                <ul>
						                    <li>Création d’un tableau de bord interactif et dynamique permettant aux utilisateurs de filtrer les données en fonction de divers critères pour une analyse approfondie.</li>
						                    <li>Utilisation de graphiques interactifs (barres, lignes, et cartes) pour visualiser les données de manière claire et engageante.</li>
						                </ul>
						            </li>
						        </ul>
						        
						        <p><strong>Environnement technique et méthodologique :</strong> SQL, Google Cloud BigQuery, Looker Studio, optimisation de requêtes, création de tableaux de bord interactifs</p>
						    </div>
						    <div class="flex-shrink-0"><span class="date">Octobre 2023 - Décembre 2023</span></div>
						</div>
						<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
						    <div class="flex-grow-1">
						        <h3 class="mb-0">Analyse et Prédiction des Objets Perdus à la SNCF</h3>
						        <div class="subheading mb-3">Aix-Marseille School of Economics – Marseille</div>
						        
						        <p><strong>Projet :</strong> Prédiction des tendances et de la répartition géographique des objets perdus à la SNCF</p>
								  
						        <p><a href="https://github.com/leaaumagy/Projets/tree/main/Objets%20perdus%20SNCF target="_blank">GitHub - Objects perdus SNCF</a></p>

								  <p>Développement d’un modèle prédictif pour anticiper les tendances et la répartition géographique des objets perdus dans les gares et les trains de la SNCF, permettant d’optimiser les procédures de récupération et d’information des voyageurs, avec pour objectif d'augmenter le taux de restitution.</p>
						        
						        <p><strong>Réalisations :</strong></p>
						        <ul>
						            <li><strong>Collecte et préparation des données :</strong>
						                <ul>
						                    <li><strong>Extraction de données :</strong> Données fournies en open data par la SNCF, incluant des informations comme la date, le lieu (gare ou train), et la catégorie de l’objet (vêtements, électronique, etc.).</li>
						                    <li><strong>Nettoyage des données :</strong> Suppression des doublons et valeurs manquantes, transformation des données catégorielles en variables quantitatives exploitables.</li>
						                    <li><strong>Analyse exploratoire des données (EDA) :</strong> Visualisation des volumes d’objets perdus selon les gares, les périodes de l’année et les catégories d’objets, à l’aide de graphiques.</li>
						                </ul>
						            </li>
						            
						            <li><strong>Modélisation des données :</strong>
						                <ul>
						                    <li>Utilisation d’une régression linéaire pour estimer les pertes d'objets en fonction du jour, de la semaine, du mois et d’autres indicateurs pertinents.</li>
						                </ul>
						            </li>
						            
						             <li><strong>Interprétation et visualisation des résultats :</strong>
						                <ul>
						                    <li><strong>Analyse des facteurs influents :</strong> Identification des facteurs associés aux pertes d’objets, comme les gares principales, les jours de forte affluence et les types d’objets les plus souvent oubliés.</li>
						                    <li><strong>Visualisation des prédictions :</strong> Création de graphiques Treemap et de cartes pour illustrer la répartition géographique des objets perdus.</li>
						                </ul>
						            </li>
						        </ul>
						        
						        <p><strong>Environnement technique et méthodologique :</strong> Python, Plotly, Seaborn, machine learning, régression linéaire, métriques d’évaluation avec RMSE, MAE et score R²</p>
						    </div>
							<div class="flex-shrink-0"><span class="date">Avril 2022</span></div>

						            </div>
        </section>
    </div>
    <!-- Bootstrap core JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Core theme JS -->
    <script src="scripts.js"></script>
</body>
</html>
